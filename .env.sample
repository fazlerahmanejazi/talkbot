# TalkBot - Environment Configuration
# ===================================

# Server Configuration
VHYS_HOST=0.0.0.0
VHYS_PORT=8080

# Audio Configuration
VHYS_SAMPLE_RATE=16000
VHYS_CHANNELS=1
VHYS_FRAME_MS=20
VHYS_PCM_WIDTH=2

# Feature Flags
VHYS_USE_PIPER=true
VHYS_ENABLE_LLM_FALLBACK=false

# AI Models
VHYS_FASTER_WHISPER_MODEL=tiny.en
VHYS_PIPER_BIN=piper
VHYS_PIPER_MODEL_PATH=./models/en_US/amy/medium/en_US-amy-medium.onnx
VHYS_PIPER_CONFIG_PATH=./models/en_US/amy/medium/en_US-amy-medium.onnx.json

# Metrics
VHYS_METRICS_DIR=./metrics
VHYS_METRICS_FILE=./metrics/latency.ndjson

# LLM Configuration
OPENAI_API_KEY="key"
VHYS_LLM_MODEL=gpt-4o-mini
VHYS_LLM_LOG=true

# Performance Optimizations
VHYS_ENABLE_PARTIALS=true
VHYS_PARTIAL_INTERVAL_MS=500
VHYS_PARTIAL_THRESHOLD_MS=200
VHYS_ENABLE_PARALLEL_LLM_TTS=true
VHYS_PARALLEL_TTS_START_DELAY_MS=100
VHYS_PARALLEL_MAX_WAIT_MS=2000
VHYS_ENABLE_STREAMING_ASR=true
VHYS_ENABLE_FULL_PARALLEL=true
VHYS_STREAMING_ASR_INTERVAL_MS=200
VHYS_STREAMING_ASR_MIN_CHARS=3
VHYS_FULL_PARALLEL_MAX_WAIT_MS=3000

# Local LLM Configuration (Optional)
VHYS_USE_LOCAL_LLM=false
VHYS_LOCAL_LLM_MODEL=llama3.2:1b
VHYS_LOCAL_LLM_HOST=http://localhost:11434
VHYS_LOCAL_LLM_TIMEOUT=30
VHYS_LOCAL_LLM_MAX_TOKENS=80
VHYS_LOCAL_LLM_TEMPERATURE=0.2
VHYS_LLM_FALLBACK_TO_OPENAI=true